%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% The Legrand Orange Book
% LaTeX Template
% Version 2.0 (9/2/15)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Mathias Legrand (legrand.mathias@gmail.com) with modifications by:
% Vel (vel@latextemplates.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
% Compiling this template:
% This template uses biber for its bibliography and makeindex for its index.
% When you first open the template, compile it from the command line with the 
% commands below to make sure your LaTeX distribution is configured correctly:
%
% 1) pdflatex main
% 2) makeindex main.idx -s StyleInd.ist
% 3) biber main
% 4) pdflatex main x 2
%
% After this, when you wish to update the bibliography/index use the appropriate
% command above and make sure to compile with pdflatex several times 
% afterwards to propagate your changes to the document.
%
% This template also uses a number of packages which may need to be
% updated to the newest versions for the template to compile. It is strongly
% recommended you update your LaTeX distribution if you have any
% compilation errors.
%
% Important note:
% Chapter heading images should have a 2:1 width:height ratio,
% e.g. 920px width and 460px height.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[11pt,fleqn]{book} % Default font size and left-justified equations

%----------------------------------------------------------------------------------------

\input{structure} % Insert the commands.tex file which contains the majority of the structure behind the template

\begin{document}

%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------

\begingroup
\thispagestyle{empty}
\begin{tikzpicture}[remember picture,overlay]
\coordinate [below=12cm] (midpoint) at (current page.north);
\node at (current page.north west)
{\begin{tikzpicture}[remember picture,overlay]
\node[anchor=north west,inner sep=0pt] at (0,0) {\includegraphics[width=\paperwidth]{background}}; % Background image
\draw[anchor=north] (midpoint) node [fill=ocre!30!white,fill opacity=0.6,text opacity=1,inner sep=1cm]{\Huge\centering\bfseries\sffamily\parbox[c][][t]{\paperwidth}{\centering The Search for a Title\\[15pt] % Book title
{\Large A Profound Subtitle}\\[20pt] % Subtitle
{\huge Dr. John Smith}}}; % Author name
\end{tikzpicture}};
\end{tikzpicture}
\vfill
\endgroup

%----------------------------------------------------------------------------------------
%	COPYRIGHT PAGE
%----------------------------------------------------------------------------------------

\newpage
~\vfill
\thispagestyle{empty}

\noindent Copyright \copyright\ 2013 John Smith\\ % Copyright notice

\noindent \textsc{Published by Publisher}\\ % Publisher

\noindent \textsc{book-website.com}\\ % URL

\noindent Licensed under the Creative Commons Attribution-NonCommercial 3.0 Unported License (the ``License''). You may not use this file except in compliance with the License. You may obtain a copy of the License at \url{http://creativecommons.org/licenses/by-nc/3.0}. Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \textsc{``as is'' basis, without warranties or conditions of any kind}, either express or implied. See the License for the specific language governing permissions and limitations under the License.\\ % License information

\noindent \textit{First printing, March 2013} % Printing/edition date

%----------------------------------------------------------------------------------------
%	TABLE OF CONTENTS
%----------------------------------------------------------------------------------------

\chapterimage{chapter_head_1.pdf} % Table of contents heading image

\pagestyle{empty} % No headers

\tableofcontents % Print the table of contents itself

\cleardoublepage % Forces the first chapter to start on an odd page so it's on the right

\pagestyle{fancy} % Print headers again

%----------------------------------------------------------------------------------------
%	PART
%----------------------------------------------------------------------------------------

\part{Part One}

%----------------------------------------------------------------------------------------
%	CHAPTER 1
%----------------------------------------------------------------------------------------

\chapterimage{chapter_head_2.pdf} % Chapter heading image

\chapter{}

\section{Lecture 1, August 24}

\begin{definition}[Field] \label{def:1.1}
	A class $\mathcal{F}$ of subsets of a non-empty set $\Omega$ is called a \emph{field} if it satisfies
	\begin{enumerate}
		\item $\varnothing \in \mathcal{F}$ and $\Omega \in \mathcal{F}$
		\item If $A \in \mathcal{F}$, then $A^c \in \mathcal{F}$ (closed under complementation)
		\item If $A \in \mathcal{F}$ and $B \in \mathcal{F}$, then $A \cup B \in \mathcal{F}$ (closed under finite unions)
	\end{enumerate}
	\emph{Note}: The term \emph{algebra} is often used to denote a field.
\end{definition}

\begin{definition}[$\sigma$-Field] \label{def:1.2}
	A field is a \emph{$\sigma$-field} or \emph{$\sigma$-algebra} if it is closed under countable unions. That is, if $A_n \in \mathcal{F}$ is a $\sigma$-field, then $\bigcup_{n=1}^\infty A_n \in \mathcal{F}$.
\end{definition}

\begin{remark} \label{rem:1.1}
	A field is a \emph{set of sets}. Suppose we are flipping a coin twice, so the sample space is $\Omega = \{\textrm{HH, HT, TH, TT}\}$. We observe an event $A \subset \Omega$, say $A = \{\textrm{TT}\}$. If we consider the set of sets $\mathcal{G} = \{\varnothing, \Omega, A, A^c\}$, then we \emph{cannot} say $\textrm{TT} \in \mathcal{G}$. Rather, we should write $\{\textrm{TT}\} \in \mathcal{G}$ or $A \in \mathcal{G}$. 
\end{remark}

The following are some examples of fields.

\begin{itemize}
	\item $\{\varnothing, \Omega\}$
	\item $\{\varnothing, \Omega, A, A^c\}$
\end{itemize}

The above are very easy to verify using the three properties of Definition~\ref{def:1.1}. The next three take a little more thought.

\begin{example}[Finite-cofinite field] \label{ex:1.1}
	Define the set $\mathcal{F} = \{A:\;\textrm{either $A$ is finite or $A^c$ is finite}\}$. The term ``finite-cofinite'' comes from this definition. Every element is either finite, or its complement is. Suppose our sample space is the natural numbers, $\Omega = \{1,2,3,\dots\}$. Clearly $\varnothing \in \mathcal{F}$ and $\Omega \in \mathcal{F}$, satisfying property 1.

	For property 2, suppose $A \in \mathcal{F}$. Again, this means that either $A$ is finite or $A^c$ is. If $A$ is finite, then $A^c \in \mathcal{F}$ because $(A^c)^c = A$ is finite. If $A^c$ is finite, then $A^c \in \mathcal{F}$ by our construction of $\mathcal{F}$. Either way, we see that $A^c \in \mathcal{F}$ and therefore property 2 holds.

	For property 3, there are four cases in which $A \in \mathcal{F}$ and $B \in \mathcal{F}$: $A$ and $B$ are finite, $A^c$ and $B$ are finite, $A$ and $B^c$ are finite, or $A^c$ and $B^c$ are finite. Obviously if $A$ and $B$ are finite then $A \cup B$ is also finite and $A \cup B \in \mathcal{F}$. If $A^c$ and $B$ are finite, then $(A \cup B)^c = A^c \cap B^c \subset A^c$, so $(A \cup B)^c$ is finite and $A \cup B \in \mathcal{F}$. This argument shows that $A \cup B \in \mathcal{F}$ in the third and fourth cases as well. Therefore property 3 holds, and we can conclude that $\mathcal{F}$ is a field.

	We might also ask whether $\mathcal{F}$ is a $\sigma$-field. Take $A_1 = \{2\}$, $A_2 = \{4\}$, $\dots$, $A_n = \{2n\}$. Then $\bigcup_{n=1}^\infty A_n = \{2,4,6,8,\dots\}$, the set of all even integers. This is an infinite set, as is its complement, the set of all odd integers. Thus $\bigcup_{n=1}^\infty A_n \notin \mathcal{F}$, meaning that $\mathcal{F}$ is a field but \emph{not} a $\sigma$-field.
\end{example}

\begin{example}[Countable-cocountable field] \label{ex:1.2}
	Define the set $\mathcal{F} = \{A:\;\textrm{either $A$ is countable}$ $\textrm{or $A^c$ is countable}\}$. Suppose the sample space is some infinite set. Again, property 1 is satisfied because $\varnothing \in \mathcal{F}$ and $\Omega \in \mathcal{F}$. The arguments for why properties 2 and 3 are satisfied follow the same reasoning in Example~\ref{ex:1.1}.

	Is $\mathcal{F}$ a $\sigma$-field? If $\Omega$ is a countable set, then $\mathcal{F} = \mathcal{P}(\Omega)$, the \emph{power set} of $\Omega$ (simply the set of all possible subsets of $\Omega$). $\mathcal{F}$ is a $\sigma$-field, because any $\bigcup_{n=1}^\infty A_n$ is a subset of $\Omega$, and therefore is contained in $\mathcal{F}$. If $\Omega$ is uncountable, then $\mathcal{F}$ is still a $\sigma$-field.
\end{example}

The previous two examples show two sets that appear similar and are both fields, but the one in Example~\ref{ex:1.2} is a $\sigma$-field whereas the one in Example~\ref{ex:1.1} is not.

\begin{example} \label{ex:1.3}
	Define $\mathcal{I} = \{(a,b]:\;0 \leq a \leq b \leq 1\}$. Then if we take $\mathcal{B}_0 = \{\varnothing, \textrm{ all finite disjoint}$ $\textrm{ unions of sets from } \mathcal{I}\}$, it turns out that $\mathcal{B}_0$ is a field on $(0,1]$. Again, it is easy to verify that properties 1 and 2 hold. Next, take $A = \bigcup_{i=1}^k I_i$ and $B = \bigcup_{j=1}^m I_j$. Then $A^c = \bigcap_{i=1}^k I_i^c$, which is still a finite union of disjoint intervals. So $A^c \in \mathcal{B}_0$, and $\mathcal{B}_0$ is indeed a field.

	To determine whether it is a $\sigma$-field, take $A_n = (0,1-\frac{1}{n}]$. Then $\bigcup_{n=1}^\infty A_n = (0,1)$. This open interval cannot be written as a finite disjoint union of intervals, so $\mathcal{B}_0$ is \emph{not} a $\sigma$-field.
\end{example}

In the following definitions, let $\mathcal{A}$ be a class of subsets of a non-empty set $\Omega$.

\begin{definition} \label{def:1.3}
	The field \emph{generated} by $\mathcal{A}$ is the smallest field containing $\mathcal{A}$:
	\[
		f(\mathcal{A}) = \bigcap_{\textrm{field } \mathcal{G} \supset \mathcal{A}} \mathcal{G}.
	\]

	The $\sigma$-field \emph{generated} by $\mathcal{A}$ is the smallest $\sigma$-field containing $\mathcal{A}$:
	\[
		\sigma(\mathcal{A}) = \bigcap_{\sigma-\textrm{field } \mathcal{G} \supset \mathcal{A}} \mathcal{G}.
	\]
\end{definition}

A very useful $\sigma$-field is the \emph{Borel $\sigma$-field}.

\begin{definition} \label{def:1.4}
	$\mathcal{B} = \sigma(\mathcal{I}) = \sigma(\mathcal{B}_0) = \sigma(\mathcal{I}_0) = \sigma(\textrm{open sets}) = \sigma(\textrm{open intervals})$ is the \emph{Borel $\sigma$-field} on $(0,1]$, where $\mathcal{I}_0 = \{(a,b] \in \mathcal{I}:\;a,b$ rationals$\}$. Sets in $\mathcal{B}$ are called \emph{Borel sets}.
\end{definition}

\section{Lecture 2, August 26}

We will now show that $\sigma(\mathcal{I}_0) = \sigma(\mathcal{I})$. It is clear from the definitions of the sets that $\mathcal{I}_0 \subset \mathcal{I}$, so trivially $\sigma(\mathcal{I}_0) \subset \sigma(\mathcal{I})$. Now suppose $(a,b] \in \mathcal{I}$. We can always find $a_n \in (a,b]$ such that $a_n$ is rational and $a_n \downarrow a$, meaning that the sequence of $a_n$'s decreases and approaches $a$. Then taking the infinite union $\bigcup_{n=1}^\infty (a_n,b] = (a,b]$. Similarly, we can find a rational $b_n$ such that $b_n \downarrow b$. Then $\bigcap_{n=1}^\infty (a_n,b_n] = (a_n,b]$, and each $(a_n,b_n] \in \mathcal{I}_0$. Thus $\mathcal{I} \subset \sigma(\mathcal{I}_0) \subset \sigma(\mathcal{I})$, meaning that $\sigma(\mathcal{I}) \subset \sigma(\mathcal{I}_0) \subset \sigma(\mathcal{I})$. We can conclude from this that $\sigma(\mathcal{I}) = \sigma(\mathcal{I}_0)$.

\begin{remark}\label{rem:1.2}
	A $\sigma$-field is \emph{countably generated}, or \emph{separable}, if it is generated by some countable class of sets.
\end{remark}

\begin{theorem} \label{thm:1.1}
	For a nonempty class $\mathcal{A}$, the field $f(\mathcal{A})$ generated by $\mathcal{A}$ is minimal (if $\mathcal{H}$ is a field and $\mathcal{A} \subset \mathcal{H}$, then $f(\mathcal{A}) \subset \mathcal{H}$) and has the form
	\[
		\mathcal{G} = f(\mathcal{A}) = \left\{\bigcup_{i=1}^m \bigcap_{j=1}^{n_i} A_{ij}:\;A_{ij} \textrm{ or } A_{ij}^c \in \mathcal{A},\;\bigcap_{j=1}^{n_i} A_{ij} \textrm{ are disjoint}\right\}.
	\]
	In short, the sets in $f(\mathcal{A})$ can be explicitly presented, which is not generally true of the sets in $\sigma(\mathcal{A})$.
\end{theorem}

\begin{proof}
	Clearly $\mathcal{A} \subset \mathcal{G}$, and any field containing $\mathcal{A}$ will also contain $\mathcal{G}$. So the ``minimality'' idea will hold, and all that remains is to show that $\mathcal{G}$ is indeed a field.

	Take $C = \bigcup_{i=1}^m \bigcap_{j=1}^{n_i} A_{ij}$ and $D = \bigcup_{s=1}^k \bigcap_{l=1}^{r_s} B_{sl}$ such that $C,D \in \mathcal{G}$. That is, all $\bigcap_{j=1}^{n_i} A_{ij}$ and $\bigcap_{l=1}^{r_s} B_{sl}$ are disjoint, either $A_{ij}$ or $A_{ij}^c$ are in $\mathcal{A}$, and either $B_{sl}$ or $B_{sl}^c$ are in $\mathcal{A}$. Then $C \cup D = \bigcup_{i=1}^m \bigcup_{s=1}^k \left( \bigcap_{j=1}^m A_{ij} \right) \cap \left( \bigcap_{l=1}^{r_s} B_{sl} \right)$. Everything to the right of the first union is disjoint, so $C \cup D \in \mathcal{G}$. Furthermore, $C^c = \bigcap_{i=1}^m \bigcup_{j=1}^{n_i} A_{ij}^c = \bigcup_{j=1}^{n_i} \left( A_{ij}^c \cap \bigcap_{k=1}^{j-1} A_{ik} \right)$, and again everything in the parentheses is disjoint, so $C^c \in \mathcal{G}$. Therefore $\mathcal{G}$ is a field.
\end{proof}

As an example of this fact, consider again the class $\mathcal{I} = \{(a,b]:\;0 \leq a \leq b \leq 1\}$, where $\Omega = (0,1]$. Here, using Theorem~\ref{thm:1.1}, $f(\mathcal{I}) = \{\varnothing, \textrm{ finite disjoint unions of intervals}\}$. There is no such nice description of the Borel $\sigma$-field $\mathcal{B}$, or of $\sigma$-fields in general.

\vspace{10pt}

Some elementary properties of fields:

\begin{enumerate}
	\item If $\mathcal{A}$ consists of singleton sets, then $f(\mathcal{A})$ is the finite-cofinite field $f(\mathcal{A}) = \{A:\;$ either $A$ is finite or $A^c$ is finite$\}$.
	\item $f(\mathcal{A}) \subset \sigma(\mathcal{A})$.
	\item If $\mathcal{A}$ is finite, then $f(\mathcal{A}) = \sigma(\mathcal{A})$.
	\item If $\mathcal{A}$ is countable, then $f(\mathcal{A})$ is countable.
	\item If $\mathcal{F}_1$ and $\mathcal{F}_2$ are fields, then $f(\mathcal{F}_1 \cup \mathcal{F}_2) = \mathcal{G}$, where
	\[
		\mathcal{G} = \left\{ \bigcup_{i=1}^m \left( A_i \cap B_i \right):\;A_i \in \mathcal{F}_1,\;B_i \in \mathcal{F}_2,\;A_i \cap B_i \textrm{ are disjoint} \right\}.
	\]
	This can be seen by noting that $\mathcal{G}$ is closed under intersections, and $A^c \cap B^c = A^c \cup (A \cap B^c)$. The important fact here is that the union of two fields is not necessarily a field itself. For example, let $\Omega = \{1,2,3,4\}$, $A = \{1\}$, $B = \{2\}$, $\mathcal{F}_1 = \{\varnothing, \Omega, A, A^c\}$, and $\mathcal{F}_2 = \{\varnothing, \Omega, B, B^c\}$. Then $\mathcal{F}_1 \cup \mathcal{F}_2 = \{\varnothing, \Omega, A, B, A^c, B^c\}$, which is not a field because $A \cup B$ is not there.
	\item If $\mathcal{F}_n \subset \mathcal{F}_{n+1}$ are fields, then $\bigcup_n \mathcal{F}_n$ is a field. However, it is not necessarily a $\sigma$-field, even if the $\mathcal{F}_n$ are all $\sigma$-fields. For example, let $\Omega = \{1,2,3,\dots\}$ and $\mathcal{F}_n = \sigma(\left\{\{k\}:\;1 \leq k \leq n \right\})$. Then $\bigcup_n \mathcal{F}_n$ is the finite-cofinite field, which we have already seen is not a $\sigma$-field.
	\item $\sigma(\mathcal{A})$ is countably generated (separable) if $\mathcal{A}$ is countable.
	\item The Borel $\sigma$-field $\mathcal{B} = \sigma(\{(a,b]:\;0 \leq a \leq b \leq 1$ rationals$\})$ is countably generated.
	\item $\mathcal{F} = \{A \subset (0,1]:\;A$ or $A^c$ is countable$\}$ is \emph{not} countably generated. To show this, suppose $\mathcal{F} = \sigma(\{A_1,A_2,\dots\}) = \sigma(\{B_1,B_2,\dots\})$, where $B_i = A_i$ if $A_i$ is countable, or $B_i = A_i^c$ if $A_i$ is not countable. In short, we are assuming that $\mathcal{F}$ is separable, and we will work towards a contradiction. We have constructed every $B_i$ to be countable, and so we can define $\Omega_0 = \bigcup_{i=1}^\infty B_i$ that is countable as well. Now $\mathcal{F} = \sigma(\mathcal{A}_0)$, where $\mathcal{A}_0 = \{\{x\}:\;x \in \Omega_0\}$. Since $\mathcal{A}_0 \subset \mathcal{G} = \{B,\;B \cup \Omega_0^c:\;B \subset \Omega_0\} \subset \mathcal{F}$, and $\mathcal{G}$ is a $\sigma$-field, it follows that $\mathcal{G} = \mathcal{F}$. But if $y \in \Omega_0^c$, then $\{y\} \notin \mathcal{G}$. This is a contradiction, and so $\mathcal{F}$ is not separable.
	\item If $\mathcal{F}_1 \subset \mathcal{F}_2$ and $\mathcal{F}_2$ is countably generated, then $\mathcal{F}_1$ need not be countably generated. This is counterintuitive, but it is readily apparent from the previous examples; suppose $\mathcal{F}_1$ is the countable-cocountable $\sigma$-field on $(0,1]$ and $\mathcal{F}_2 = \mathcal{B}$, the Borel $\sigma$-field. 
\end{enumerate}

\section{Lecture 3, August 28}

\begin{definition}[Probability] \index{Probability} \label{def:probability}
	Let $\mathcal{F}$ be a field on a nonempty set $\Omega$. A set function $P$ on $\mathcal{F}$ is called a \emph{probability} if it satisfies
	\begin{enumerate}[label=(\Roman*)]
		\item $0 \leq P(A) \leq 1$ for all $A \in \mathcal{F}$
		\item $P(\varnothing) = 0$ and $P(\Omega) = 1$
		\item \emph{Countable additivity} --- If $A_n$ are disjoint sets in $\mathcal{F}$, and $\bigcup_{n=1}^\infty A_n \in \mathcal{F}$, then $P \left( \bigcup_{n=1}^\infty A_n \right) = \sum_{n=1}^\infty P(A_i)$
		\item \emph{Finite additivity} --- For $A_i \in \mathcal{F}$ disjoint, $P \left( \bigcup_{i=1}^n A_i \right) = \sum_{i=1}^n P(A_i)$
		\item \emph{Countable subadditivity} --- If $B_n$, $\bigcup_{n=1}^\infty B_n \in \mathcal{F}$ then $P \left( \bigcup_{n=1}^\infty B_n \right) \leq \sum_{n=1}^\infty P(B_n)$.
	\end{enumerate}
	The inequality in (V) is known as \emph{Boole's Inequality}.
\end{definition}

Under conditions (I) and (II), condition (III) implies (IV) and (V), and conversely (IV) and (V) together imply (III). The latter will now be proven.

\begin{proof}
	Suppose $A_n \in \mathcal{F}$ are disjoint, $\bigcup_{n=1}^\infty A_n \in \mathcal{F}$, and conditions (IV) and (V) hold. Then
	\[
		\sum_{i=1}^n P(A_i) = P \left( \bigcup_{i=1}^n A_i \right) \leq P \left( \bigcup_{i=1}^\infty A_i \right) \leq \sum_{i=1}^\infty P(A_i).
	\]
	Letting $n \rightarrow \infty$, we have
	\[
		\sum_{i=1}^\infty P(A_i) \leq P \left( \bigcup_{i=1}^\infty A_i \right) \leq \sum_{i=1}^\infty P(A_i)
	\]
	and therefore $P \left( \bigcup_{i=1}^\infty A_i \right) = \sum_{i=1}^\infty P(A_i)$ as desired.
\end{proof}

Note that (IV) alone does not guarantee (III). Take a nonempty sample space $\Omega = \{1,2,\dots\}$ and $\mathcal{F}$ to be the finite-cofinite field. Furthermore, define $P$ to be a function on $\mathcal{F}$ where
\[
	P(A) = \begin{cases}
		0 & \textrm{if } A \textrm{ is finite} \\
		1 & \textrm{if } A^c \textrm{ is finite}.
	\end{cases}
\]
It is clear that properties (I) and (II) hold in this case. (IV) also holds: Take $A$, $B$ disjoint (so $A \cap B = \varnothing$). If both $A$ and $B$ are finite, then the union is also finite, so $P(A \cup B) = 0 = P(A) + P(B)$. If one is cofinite, then $A \cup B$ is cofinite, so $P(A \cup B) = 1 = P(A) + P(B)$. If both are cofinite, then it turns out that $A$ and $B$ could not have been disjoint in the first place. This is because $(A \cap B)^c = A^c \cup B^c$ is finite, so $A \cap B$ must be cofinite and therefore $A \cap B \neq \varnothing$. So we don't need to consider this case at all.

On the other hand, define $A_n = \{n\}$. The $A_n$ are disjoint, and $\bigcup_{n=1}^\infty A_n = \Omega \in \mathcal{F}$. However, each $P(A_n) = 0$, so $\sum_{n=1}^\infty P(A_i) = 0$, yet $P(\bigcup_{n=1}^\infty A_n) = P(\Omega) = 1$. Countable additivity fails.

\begin{remark}
	If we have a general, non-disjoint group of sets $B_1,B_2,\dots \in \mathcal{F}$, we can construct a disjoint group $A_1,A_2,\dots$ such that the union of all sets in each group are the same. This process of \emph{disjointification} often proves useful. Define
	\begin{align*}
		A_1 &= B_1 \\
		A_2 &= B_2 \cap B_1^c \\
		A_3 &= B_3 \cap B_2^c \cap B_1^c \\
		&\vdots \\
		A_n &= B_n \cap \left( \bigcup_{j < n} B_j \right)^c.
	\end{align*}
	Then $\bigcup_{i=1}^n A_i = \bigcup_{i=1}^n B_i$, and the $A_i$ are disjoint.
\end{remark}

We can use disjointification to prove some useful statements. For example, we can show that if $C \subset D$, then $P(C) \leq P(D)$:
\begin{align*}
	D &= C \cup (D \cap C^c) \tag{by disjointification} \\
	P(D) &= P(C) + P(D \cap C^c) \\
	&\geq P(C) \tag{probability is non-negative}.
\end{align*}

\begin{definition}[Continuity from below/above] \label{def:continuity-from-below}
	If $A_n \in \mathcal{F}$, $A \in \mathcal{F}$, and $A_n \uparrow A$ (meaning that $A_1 \subset A_2 \subset \cdots \subset A_n$ and $\bigcup_i A_i = A$), then $P(A_n) \uparrow P(A)$. This is called \emph{continuity from below}.

	Similarly, if $B_n \in \mathcal{F}$, $B \in \mathcal{F}$, and $B_n \downarrow B$ (meaning that $B_1 \supset B_2 \supset \cdots \supset B_n$ and $\bigcap_i B_i = B$), then $P(B_n) \downarrow P(B)$. This is called \emph{continuity from above}.
\end{definition}

Recall the function $P$ defined earlier:
\[
	P(A) = \begin{cases}
		0 & \textrm{if } A \textrm{ is finite} \\
		1 & \textrm{if } A^c \textrm{ is finite}.
	\end{cases}
\]
This is \emph{not} a probability on $\Omega = \{1,2,\dots\}$. Continuity from below is not satisfied. To see this, define $A_n = \{1,2,\dots\}$. $A_n$ is finite, so $P(A_n)=0$. Then $A_n \uparrow \Omega = \{1,2,3,\dots\}$, but $P(\Omega)=1$.

\begin{theorem} \label{thm:1.2}
	Countable additivity implies $P(C_n) \downarrow 0$ whenever $C_n \in \mathcal{F}$ and $C_n \downarrow \varnothing$.
\end{theorem}

\begin{proof}
	Suppose we have a sequence of sets $C_n$ such that $C_n \downarrow \varnothing$. That is, $C_1 \supset C_2 \supset \cdots \supset C_n$. Construct a sequence of sets $A_n$ in the following way:
	\begin{align*}
		A_1 &= C_1 - C_2 \\
		A_2 &= C_2 - C_3 \\
		&\vdots \\
		A_n &= C_n - A_{n+1}.
	\end{align*}
	Then the $A_n$ are disjoint, and $C_n = \bigcup_{i=n}^\infty A_i$. Note that this means that $C_1 = \bigcup_{i=1}^\infty A_i$. Now $P(C_1) = P \left( \bigcup_{i=1}^\infty A_i \right) = \sum_{i=1}^\infty P(A_i) \leq 1 < \infty$, by countable additivity. Thus $P(C_n) = \sum_{i=n}^\infty P(A_i) \rightarrow 0$ because it is the tail of a converging series.
\end{proof}

We will now prove that Theorem~\ref{thm:1.2} and finite additivity together imply countable additivity.

\begin{proof}
	If we define $D_n = \bigcup_{i=1}^n A_i$ and $D = \bigcup_{i=1}^\infty A_i$, then $D - D_n \downarrow \varnothing$ and $P(D-D_n) \downarrow 0$. Now $P(D) = P(D-D_n) + P(D_n)$, and $P(D_n) = \sum_{i=1}^n P(A_i) \rightarrow \sum_{i=1}^\infty P(A_i)$.
\end{proof}

Furthermore, Theorem~\ref{thm:1.2} implies continuity from above and continuity from below.

\begin{definition}[Probability space] \label{def:probability-space}
	If $\mathcal{F}$ is a $\sigma$-field on $\Omega$ and $P$ is a probability measure on $\mathcal{F}$, the triple $(\Omega,\mathcal{F},P)$ is called a \emph{probability measure space}, or simply a \emph{probability space}.
\end{definition}

The following examples illustrate the concept of a probability space.

\begin{example} \label{ex:1.4}
	Let $\mathcal{F}$ be the finite-cofinite field on some nonempty set $\Omega$, and let $P$ be defined such that $P(A) = 0$ or 1 depending on whether $A$ is finite or not. If $\Omega$ is a countable set, then $P$ is not a probability (as we saw earlier). However, if $\Omega$ is uncountable, then $P$ is a valid probability, and $(\Omega,\mathcal{F},P)$ is a probability space.
\end{example}

\begin{example} \label{ex:1.5}
	Let $\mathcal{F}$ be the countable-cocountable $\sigma$-field on an uncountable set $\Omega$. Define $P$ such that $P(A) = 0$ or 1 depending on whether $A$ is countable or not. Then $P$ is a probability measure, and $(\Omega,\mathcal{F},P)$ is a probability space.
\end{example}

\begin{example} \label{ex:1.6}
	Let $\Omega = (0,1]$, and define a function $\lambda(a,b) = b-a$, where $0 \leq a \leq b \leq 1$. This is our standard concept of \emph{length} for an interval. Furthermore, the length of the union of disjoint intervals is the sum of the lengths of each individual interval:
	\[
		\lambda \left( \bigcup_{i=1}^k (c_i,d_i] \right) = \sum_{i=1}^k (d_i-c_i), \qquad \textrm{$(c_i,d_i]$ are disjoint}.
	\]
	Then $\lambda$ is a (countably additive) probability measure on $\mathcal{B}_0 = f(\mathcal{I})$.
\end{example}

\section{Lecture 4, August 31}

How can we extend this $\lambda$ to $\sigma(\mathcal{I}) = \sigma(\mathcal{B}_0)$, the Borel $\sigma$-field? As previously mentioned, there is not a nice concise way to describe $\sigma$-fields. We could define $\mathcal{B}_{\sigma} = \{\bigcup_{i=1}^\infty A_i:\;A_i \in \mathcal{B}_0\}$, but this is not closed under complementation and so is not a $\sigma$-field. Then we might try $\mathcal{B}_{\sigma\delta} = \{\bigcap_{i=1}^\infty B_i:\;B_i \in \mathcal{B}_{\sigma}\}$, but this still won't work. Even if we tried an infinite sequence $\mathcal{B}_{\sigma\delta\sigma\delta\cdots}$ of these unions and intersections, we still would not be left with a $\sigma$-field. The bottom line is that we will need another way to describe them.

\begin{definition}[Outer measure] \label{def:outer-measure}
	Let $\Omega$ be a non-empty set. $P^*$ on $2^\Omega$ (also known as the power set $\mathcal{P}(\Omega)$) is an \emph{outer measure} if it satisfies the following properties.
	\begin{enumerate}[label=(\Roman*)]
		\item $P^*(\varnothing) = 0$
		\item $P^*(A) \geq 0$
		\item $P^*(A) \leq P^*(B)$ whenever $A \subseteq B$
		\item $P^*(\bigcup_i A_i) \leq \sum_i P^*(A_i)$ --- countable sub-additivity
	\end{enumerate}
\end{definition}

\begin{notation}
	For convenience, we will sometimes omit the intersection symbol $\cap$. For example, $AE = A \cap E$.
\end{notation}

A good measure should satisfy $P^*(A)+P^*(A^c)=1$ on $\sigma(\mathcal{F}_0)$. This intuitively makes sense when one thinks about the usual concept of probability. However, it turns out that this property is somewhat difficult to handle in practice. It is easier to work with something like
\[
	\mathcal{M}' = \{A \subset \Omega:\;P^*(AE)+P^*(A^cE)=P^*(E) \textrm{ for all } E \subset \Omega\}.
\]
Inequalities are even more useful, so we relax this to
\[
	\mathcal{M} = \{A \subset \Omega:\;P^*(AE)+P^*(A^cE) \leq P^*(E) \textrm{ for all } E \subset \Omega\}.
\]

We will now present and prove some facts about this particular collection based on an outer measure.

\begin{theorem} \label{thm:1.3}
	Define $\mathcal{M} = \mathcal{M}(P^*) = \{A \subset \Omega:\;P^*(AE)+P^*(A^cE) \leq P^*(E)$ for all $E \subset \Omega\}$, where $P^*$ is an outer measure on $\mathcal{F}_0$. Then
	\begin{enumerate}[label=(\alph*)]
		\item $\mathcal{M}$ is a field,
		\item If $A_i \in \mathcal{M}$ are disjoint, then $P^*(E \cap (\bigcup_i A_i)) = \sum_i P^*(EA_i)$,
		\item $\mathcal{M}$ is a $\sigma$-field and $P^*$ is countably additive on $\mathcal{M}$.
		\item $\mathcal{F}_0 \subset \mathcal{M}$
		\item $P^*$ agrees with $P$ everywhere on $\mathcal{F}_0$.
	\end{enumerate}
\end{theorem}

\begin{proof}
	The proofs for (a), (b), and (c) depend only on properties (I)-(IV) in Definition~\ref{def:outer-measure}.

	\vspace{10pt}
	First we will show (a). Recall that to prove $\mathcal{M}$ is a field, we need to verify that $\varnothing, \Omega \in \mathcal{M}$, that $\mathcal{M}$ is closed under complementation, and that it is closed under finite unions. Inspection of the definition of $\mathcal{M}$ will reveal that it is symmetric about $A$; we can switch $A$ with $A^c$ with no change. Therefore $\mathcal{M}$ is trivially closed under complementation. Also, $P^*(\varnothing \cap E) + P^*(\Omega \cap E) = P^*(E)$, so $\varnothing, \Omega \in \mathcal{M}$.

	Now we only need to show closure under finite unions. For any $A,B \in \mathcal{M}$, $(AB)^c = AB^c \cup A^cB^c \cup A^cB$ (this is easy to verify using a Venn diagram).
	\begin{align*}
		P^*(ABE) + P^*((AB)^cE) &\leq P^*(ABE) + P^*(AB^cE) + P^*(A^cB^cE) + P^*(A^cBE) \tag{by property (IV)} \\
		&\leq P^*(ABE) + P^*(B^cE) + P^*(A^cBE) \tag{because $A \in \mathcal{M}$} \\
		&\leq P^*(B^cE) + P^*(BE) \tag{because $A \in \mathcal{M}$} \\
		&\leq P^*(E) \tag{because $B \in \mathcal{M}$}.
	\end{align*}
	Therefore $AB \in \mathcal{M}$. We have shown that $\mathcal{M}$ is closed under finite intersection. If $A \cap B \in \mathcal{M}$, then so is $(A \cap B)^c = A^c \cup B^c$, and so is $A \cup B$. Thus $\mathcal{M}$ is closed under finite union as well. We can conclude that $\mathcal{M}$ is a field.

	\vspace{10pt}
	Next, we will prove (b). Suppose $A_1,A_2 \in \mathcal{M}$ and $A_1$ and $A_2$ are disjoint. Then
	\begin{align*}
		P^*(E(A_1 \cup A_2)) &= P^*(E(A_1 \cup A_2)A_1) + P^*(E(A_1 \cup A_2)A_1^c) \\
		&= P^*(EA_1)+P^*(EA_2) \tag{because $A_2 \subset A_1^c$}.
	\end{align*}
	By induction, for disjoint $A_1 \in \mathcal{M}$ we have
	\[
		P^*\left( E \cap \left( \bigcup_{i=1}^n A_i \right) \right) = \sum_{i=1}^n P^*(EA_i).
	\]
	Because $P^*(A) \geq 0$ for any $A$, It follows that $P^*(E \cap (\bigcup_{i=1}^\infty A_i)) \geq P^*(E \cap (\bigcup_{i=1}^n A_i))$. Taking the limit leads us to conclude that 
	\[
		P^* \left( E \cap \left( \bigcup_{i=1}^\infty A_i \right) \right) \geq P^*\left( E \cap \left( \bigcup_{i=1}^n A_i \right) \right) = \sum_{i=1}^n P^*(EA_i) \rightarrow \sum_{i=1}^\infty P^*(EA_i).
	\]
	But property (IV), countable subadditivity, tells us that $P^*(E \cap (\bigcup_{i=1}^\infty A_i)) \leq \sum_{i=1}^\infty P^*(EA_i)$. Therefore
	\[
		P^* \left( E \cap \left( \bigcup_{i=1}^\infty A_i \right) \right) = \sum_{i=1}^\infty P^*(EA_i)
	\]
	as desired.

	\vspace{10pt}
	Finally we show (c). We already know $\mathcal{M}$ is a field, so to show it is a $\sigma$-field all we need is closure under countable unions. Let $B_1,B_2,\cdots \in \mathcal{M}$, and $B = \bigcup_{i=1}^\infty B_i$. Disjointify the $B_i$s, so define $A_1 = B_1, \dots, A_n = B_n \cap (\bigcup_{i<n} B_i)^c$. Then all $A_i \in \mathcal{M}$, the $A_i$ are disjoint, and the unions are the same: $\bigcup_{i=1}^n A_i = \bigcup_{i=1}^n B_i \uparrow B$.
	\begin{align*}
		P^*(E) &= P^*\left(E \cap \left(\bigcup_{i=1}^n A_i\right)\right) + P^*\left(E \cap \left(\bigcup_{i=1}^n A_i\right)^c\right) \\
		&\geq \sum_{i=1}^n P^*(EA_i) + P^*(EB^c) \rightarrow \sum_{i=1}^\infty P^*(EA_i) + P^*(EB^c) \tag{taking limit as $n \rightarrow \infty$} \\
		&\geq P^*(EB) + P^*(EB^c) \tag{by property (IV)}.
	\end{align*}
	So $B = \bigcup_{i=1}^\infty B_i \in \mathcal{M}$, and hence $\mathcal{M}$ is a $\sigma$-field. We can easily see that $P^*$ is countably additive on $\mathcal{M}$ by taking $E = \Omega$ in (b).
\end{proof}

Again, to this point we have used only properties (I)-(IV) in Definition~\ref{def:outer-measure}.

\section{Lecture 5, September 2}

Now, assume that $P$ is a probability measure on a field $\mathcal{F}_0$ of subsets of a nonempty set $\Omega$. Define
\[
	P^*(E) = \inf \left\{ \sum_i P(A_i):\;E \subset \bigcup_i A_i, \textrm{ and } A_i \in \mathcal{F}_0 \right\}.
\]
This $P^*$ satisfies all four properties of Definition~\ref{def:outer-measure}.

\begin{proof}
	Property (I) is clearly satisfied by letting all the $A_i = \varnothing$. Also, $P$ is nonnegative on $\mathcal{F}_0$, so $P^*$ must also be nonnegative, and thus property (II) is satisfied. This non-negativity is why property (III) is satisfied as well.

	Property (IV) is a bit harder to show. Let $A_n \subset \Omega$ and fix some $\epsilon > 0$. Then
	\[
		P^*(A_n) = \inf \left\{ \sum_k P(C_{nk}):\;A_n \subset \bigcup_k C_{nk},\;C_{nk} \in \mathcal{F}_0 \right\}.
	\]
	Now there is some collection $B_{nk} \in \mathcal{F}_0$ such that $A_n \subset \bigcup_k B_{nk}$ and $\sum_k P(B_{nk}) < P^*(A_n) + \epsilon 2^{-n}$. Since $\bigcup_n A_n \subset \bigcup_n \bigcup_k B_{nk}$, we have
	\[
		P^*\left(\bigcup_n A_n\right) \leq \sum_n \sum_k P(B_{nk}) \leq \sum_n P^*(A_n) + \epsilon.
	\]
	$\epsilon$ can be taken to be arbitrarily small, and thus we have countable sub-additivity. $P^*$ is therefore an outer measure.
\end{proof}

Next we will establish the remaining two facts from Theorem~\ref{thm:1.3}.
\begin{itemize}
	\item $\mathcal{F}_0 \subset \mathcal{M}$
	\item $P^*$ agrees with $P$ everywhere on $\mathcal{F}_0$.
\end{itemize}

\begin{example}[Exercise 3.3(a)]
	Consider the following scenario: Let $\Omega = \{1,2,3\}$. The power set of $\Omega$ is $2^\Omega = \{\varnothing,\Omega,\{1\},\{2\},\{3\},\{1,2\},\{1,3\},\{2,3\}\}$. Now let $P_1(\{2,3\}) = 1$, $P_1(\{1\})=0$, and $P_2(\{2,3\})=0$, $P_2(\{1\})=1$ be two probability measures on the field $\mathcal{F}_0 = \{\varnothing,\Omega,\{1\},\{2,3\}\}$.

	First we will establish $\mathcal{F}_0 \subset \mathcal{M}(P_1^*)$.
	If $A = \{2\}$, then $P_1^*(A\Omega) = P_1^*(A) = P_1^*(\{2,3\}) = 1$ and $P_1^*(A^c\Omega) = P_1^*(A^c) = P_1^*(\{1,3\}) = 1$. But $P_1^*(\Omega) = 1$, and $1+1 > 1$. This means that $\{2\} \notin \mathcal{M}(P_1^*)$ and $\{1,3\} \notin \mathcal{M}(P_1^*)$. Similarly, we can check that $\{3\}, \{1,2\} \notin \mathcal{M}(P_1^*)$. The only sets left from $2^\Omega$ are the ones that make up $\mathcal{F}_0$, so $\mathcal{F}_0 = \mathcal{M}(P_1^*)$.

	Now we focus on $P_2^*$. For a particular $A$ and any $E$, property (III) of Definition~\ref{def:outer-measure} guarantees that $P_2^*(AE) \leq P_2^*(A)$ because $A \cap E \subseteq A$. Suppose $1 \notin A$. If this is the case, then $P_2^*(A) = 0$ (since the only two possibilities for $A$ in $\mathcal{F}$ are $\varnothing$ and $\{2,3\}$, and $P_2^*$ is zero on each of these). This establishes that $P_2^*(AE) = 0$. It is also true that $P_2^*(A^cE) \leq P_2^*(E)$, also by property (III) of Definition~\ref{def:outer-measure}. Putting these together,
	\[
		P_2^*(AE) + P_2^*(A^cE) \leq 0 + P_2^*(E)
	\]
	which indicates that $A \in \mathcal{M}(P_2^*)$ and, as a direct result, $A^c \in \mathcal{M}(P_2^*)$. This covers every possible set $A$, and therefore $\mathcal{M}(P_2^*) = 2^\Omega$.
\end{example}

We will now prove that $\mathcal{F}_0 \subset \mathcal{M}$.

\begin{proof}
	Let $A \in \mathcal{F}_0$, and $E \subset \Omega$. Let $A_i \in \mathcal{F}_0$ such that $E \subset \bigcup_{i=1}^\infty A_i$. Note that $AE \subset \bigcup_{i=1}^\infty AA_i$ and $A^cE \subset \bigcup_{i=1}^\infty A^cA_i$. So
	\[
		P^*(EA) + P^*(EA^c) \leq \sum_{i=1}^\infty P(AA_i) + \sum_{i=1}^\infty P(A^cA_i) = \sum_{i=1}^\infty P(A_i).
	\]
	So $P^*(EA) + P^*(EA^c) \leq P^*(E)$, and thus $A \in \mathcal{M}$.
\end{proof}

Only the finite additivity of $P$ was used above. Next we will show that $P^*=P$ on $\mathcal{F}_0$.

\begin{proof}
	We have already seen that $P^*(A) \leq P(A)$ if $A \in \mathcal{F}_0$. If we have some $A_i \in \mathcal{F}_0$ such that $\bigcup_{i=1}^\infty A_i \supset A$, then
	\[
		P(A) \leq \sum_{i=1}^\infty P(AA_i) \leq \sum_{i=1}^\infty P(A_i)
	\]
	by the countable sub-additivity of $P$ on $\mathcal{F}_0$. Notice that we cannot say directly that $P(A) \leq \sum_{i=1}^\infty P(A_i)$ because there is no guarantee that $\bigcup_{i=1}^\infty A_i \in \mathcal{F}_0$. The intermediate step is therefore necessary.

	The above gives us that $P(A) \leq P^*(A)$. Therefore $P^*$ restricted to $\mathcal{F}_0$ agrees with $P$, as desired.
\end{proof}

This leads us to an important result.

\begin{theorem}[Extension Theorem] \label{thm:extension}
	Every probability measure on a field $\mathcal{F}_0$ has an extension to $\sigma(\mathcal{F}_0)$.
\end{theorem}

\begin{proof}
	$\mathcal{M}$ is a $\sigma$-field containing $\mathcal{F}_0$, so $\sigma(\mathcal{F}_0) \subset \mathcal{M}$. Furthermore, $P^*$ is a probability measure on $\mathcal{M}$, and hence $P^*$ restricted to $\sigma(\mathcal{F}_0)$ is a probability measure as well. Finally, $P^*(A)=P(A)$ for all $A \in \mathcal{F}_0$.
\end{proof}

When we restrict $P^*$ to $\sigma(\mathcal{F}_0)$, then $P^*$ is defined on all subsets of $\Omega$. Define
\begin{align*}
	P_0(A) &= P^*(A) \qquad \textrm{if } A \in \mathcal{M} \\
	P_1(A) &= P^*(A) \qquad \textrm{if } A \in \sigma(\mathcal{F}_0) \\
	P_2(A) &= P^*(A) \qquad \textrm{if } A \in \mathcal{F}_0.
\end{align*}

$P_0$ is \emph{not} a probability measure on $\sigma(\mathcal{F}_0)$ or $\mathcal{F}_0$, for example. The values are the same (and are equal to the values of $P^*$), but the \emph{domains}, the collections of sets on which they are defined, differ.

Is it possible to have two probability measures, say $Q_1$ and $Q_2$, on $\sigma(\mathcal{F}_0)$ such that $Q_1=Q_2$ on $\mathcal{F}_0$? We will now work towards a uniqueness theorem. First some definitions.

\begin{definition}[$\pi$-system] \label{def:pi-system}
	A class $\mathcal{P}$ is called a \emph{$\pi$-system} if $A,B \in \mathcal{P}$ implies $AB \in \mathcal{P}$ (closed under intersection).
\end{definition}

\begin{definition}[$\lambda$-system] \label{def:lambda-system}
	A class $\mathcal{L}$ is called a \emph{$\lambda$-system} if if satisfies the following conditions:
	\begin{enumerate}[label=($\lambda$\arabic*)]
		\item $\Omega \in \mathcal{L}$
		\item $A \in \mathcal{L}$ implies $A^c \in \mathcal{L}$
		\item If $A_1,A_2,\dots \in \mathcal{L}$ and are disjoint, then $\bigcup_i A_i \in \mathcal{L}$. (Closed under countable disjoint unions)
	\end{enumerate}
\end{definition}

A $\lambda$-system is ``almost'' a $\sigma$-field. The only difference is the additional restriction of disjointness in property ($\lambda$3). Why is this distinction made? Suppose we have $P_1$ and $P_2$ such that for all $A_i$, $P_1(A_i)=P_2(A_i)$. We can't really say that
\[
	P_1 \left( \bigcup_{i=1}^\infty A_i \right) = P_2 \left( \bigcup_{i=1}^\infty A_i \right).
\]
We need disjointness to prove uniqueness.

\begin{example}[$\lambda$-system but not a $\sigma$-field] \label{ex:1.6}
	Suppose $\Omega = \{1,2,3,4\}$. Let
	\[
	\mathcal{L} = \{\varnothing, \Omega, \{1,2\}, \{2,3\}, \{3,4\}, \{1,4\}\}.
	\]
	Notice that $\mathcal{L}$ is of the form $\mathcal{L}=\{\varnothing, \Omega, A, B, A^c, B^c\}$, where $\varnothing \neq A \neq B \neq \Omega$, $A \neq B^c$, and $A \cap B \neq \varnothing$.
\end{example}

\begin{theorem} \label{thm:1.4}
	A class $\mathcal{F}$ that is both a $\pi$-system and a $\lambda$-system, is a $\sigma$-field.
\end{theorem}

\begin{proof}
	We only need to show that $\mathcal{F}$ is closed under countable unions. Let $B_i \in \mathcal{F}$. Break the $B_i$ into disjoint sets in the usual way:
	\[
		A_1 = B_1, \dots, A_n = B_n \cap \left( \bigcup_{i<n} B_i \right)^c.
	\]
	Then $A_i$ are disjoint and $\bigcup_i A_i = \bigcup_i B_i$. Since $B_i \in \mathcal{F}$, we have $B_i^c \in \mathcal{F}$ by ($\lambda$2).

	Because $\mathcal{F}$ is a $\pi$-system, we have $A_n = B_n \cap (B_1^c \cdots B_{n-1}^c) \in \mathcal{F}$. So by ($\lambda$3), $\bigcup_i A_i \in \mathcal{F}$. Hence $\mathcal{F}$ is a $\sigma$-field.
\end{proof}

\section{Lecture 6, September 4}

\begin{theorem} \label{thm:dynkin}
	If $\mathcal{P}$ is a $\pi$-system, $\mathcal{L}$ is a $\lambda$-system, and $\mathcal{P} \subset \mathcal{L}$, then $\sigma(\mathcal{P}) \subset \mathcal{L}$.
\end{theorem}

\begin{proof}
	Let $\mathcal{L}_0$ be the smallest $\lambda$-system containing $\mathcal{P}$. As $\mathcal{L}_0 \subset \mathcal{L}$, by Theorem~\ref{thm:extension} it is enough to show that $\mathcal{L}_0$ is a $\pi$-system. For any fixed $A \subset \Omega$ (where $A$ is not necessarily in $\mathcal{L}_0$), define
	\[
		\mathcal{L}_A = \{B \in \mathcal{L}_0:\;AB \in \mathcal{L}_0\}.
	\]
	Note that the intersection of $\lambda$-systems is itself a $\lambda$-system. In the context of collections of sets, ``intersection'' means sets that are common to both.

	\vspace{10pt}
	\textbf{Part 1}. First we will show that if $A \in \mathcal{L}_0$, then $\mathcal{L}_A$ is a $\lambda$-system.
	
	\begin{enumerate}
		\item If $A \in \mathcal{L}_0$, then $A \cap \Omega \in \mathcal{L}_0$. So $\Omega \in \mathcal{L}_A$, verifying property ($\lambda$1).
		\item If $A \in \mathcal{L}_0$, then $A^c \in \mathcal{L}_0$. Furthermore, if $B \in \mathcal{L}_A$, then $B \in \mathcal{L}_0$. Now consider the sets $AB$ and $A^c$. These are disjoint, and each is in $\mathcal{L}_0$. As a result, $(AB \cup A^c)^c \in \mathcal{L}_0$, and $(AB \cup A^c)^c = A \cap (AB)^c = B^cA \in \mathcal{L}_0$. We know that $B^c \in \mathcal{L}_0$, and so this implies that $B^c \in \mathcal{L}_A$. Therefore $\mathcal{L}_A$ is closed under complementation, verifying property ($\lambda$2).
		\item If $A \in \mathcal{L}_0$ and $B_n \in \mathcal{L}_0$ are disjoint, then $AB_n \in \mathcal{L}_0$ and are disjoint. So $\bigcup_n B_n \in \mathcal{L}_0$ and $A \cap \bigcup_n B_n \in \mathcal{L}_0$. This implies that $\bigcup_n B_n \in \mathcal{L}_A$, verifying property ($\lambda$3).
	\end{enumerate}

	Thus if $A \in \mathcal{L}_0$, then $\mathcal{L}_A$ is a $\lambda$-system.

	\vspace{10pt}
	\textbf{Part 2}. We will now show that $\mathcal{L}_0$ is a $\pi$-system. There are three possibilities here:

	\begin{enumerate}
		\item $A \in \mathcal{P}$, $B \in \mathcal{P}$
		\item $A \in \mathcal{P}$, $B \in \mathcal{L}_0$
		\item $A \in \mathcal{L}_0$, $B \in \mathcal{L}_0$.
	\end{enumerate}

	We must show that in each case, $A \cap B \in \mathcal{L}_0$.

	First, fix $A \in \mathcal{P}$. Then $B \in \mathcal{P}$ implies $AB \in \mathcal{P} \subset \mathcal{L}_0$. So $B \in \mathcal{L}_A$ and hence $\mathcal{P} \subset \mathcal{L}_A$. Now, we showed in Part 1 above that $\mathcal{L}_A$ is a $\lambda$-system since $A \in \mathcal{L}_0$. To this point we have showed that $A \in \mathcal{P}$ implies $\mathcal{L}_0 \subset \mathcal{L}_A$. Since we already knew that $\mathcal{L}_A \subset \mathcal{L}_0$, this actually means $A \in \mathcal{P} \implies \mathcal{L}_A = \mathcal{L}_0$.

	From the definition of $\mathcal{L}_A$, if $A \in \mathcal{P}$ and $B \in \mathcal{L}_0$, then $AB \in \mathcal{L}_0$. This is exactly what we needed for case 2.

	Now fix $B \in \mathcal{L}_0$. If $A \in \mathcal{P}$, then $AB \in \mathcal{L}_0$. This is simply a restatement of the above conclusion. This implies that $A \in \mathcal{L}_B = \{C \in \mathcal{L}_0:\;CB \in \mathcal{L}_0\}$. So $\mathcal{P} \subset \mathcal{L}_B$, which immediately implies $\mathcal{L}_0 \subset \mathcal{L}_B$ whenever $B \in \mathcal{L}_0$. Hence $\mathcal{L}_0 = \mathcal{L}_B$ for all $B \in \mathcal{L}_0$.

	The conclusion is if $A \in \mathcal{L}_0$ and $B \in \mathcal{L}_0$, then $AB \in \mathcal{L}_0$, which is case 3 above.

	\vspace{10pt}
	So $\mathcal{L}_0$ is a $\pi$-system and a $\lambda$-system, and thus by Theorem~\ref{thm:1.4} it is a $\sigma$-field. Also it contains $\mathcal{P}$, so $\mathcal{P} \subset \mathcal{L}_0 \subset \mathcal{L}$.
\end{proof}

\begin{theorem}[Uniqueness Theorem] \label{thm:uniqueness}
	Suppose $P_1$ and $P_2$ are probability measures on $\sigma(\mathcal{P})$, where $\mathcal{P}$ is a $\pi$-system. If $P_1$ and $P_2$ agree on $\mathcal{P}$, then they agree on $\sigma(\mathcal{P})$.
\end{theorem}

\begin{proof}
	Let $\mathcal{L} = \{A \in \sigma(\mathcal{P}):\;P_1(A) = P_2(A)\}$. This $\mathcal{L}$ is a $\lambda$-system (conditions are straightforward to verify), and it contains the $\pi$-system $\mathcal{P}$. By Theorem~\ref{thm:dynkin}, $\sigma(\mathcal{P}) \subset \mathcal{L}$ as required.
\end{proof}

\begin{definition}[Support] \label{def:support}
	$S \in \mathcal{F}$ is called a \emph{support} of $P$ if $P(S)=1$.
\end{definition}

\begin{definition}[Null-set] \label{def:null-set}
	A set with probability measure zero is called a \emph{null-set}.
\end{definition}

\begin{definition}[Completeness] \label{def:completeness}
	A probability measure space $(\Omega,\mathcal{F}_0,P_0)$ is \emph{complete} if
	\[
		A \subset B, \; B \in \mathcal{F}_0, \textrm{ and } P_0(B) = 0 \implies A \in \mathcal{F}_0.
	\]
	That is, if there is a null-set in $\mathcal{F}_0$, all its subsets are also in $\mathcal{F}_0$.
\end{definition}

The Borel $\sigma$-field $\mathcal{B}$ is \emph{not} complete. There exist uncountable subsets which are still measure zero. Cantor sets, on the other hand, are complete.

\section{Lecture 7, September 9}

It is always possible to complete a probability space.

\begin{theorem} \label{thm:complete-extension}
	For every probability space, there exists a unique minimal complete extension.
\end{theorem}

\begin{proof}
	For any probability space $(\Omega,\mathcal{F},P)$, define the outer measure $P^*$ using $\mathcal{F}_0$ such that $\mathcal{F} = \sigma(\mathcal{F})$. Then $P^*$ restricted to $\mathcal{M}(P^*)$ is a probability measure: If $P^*(B) = 0$ and $A \subset B$, then $P^*(A)=0$ and $P^*(A \cap E) + P^*(A^c \cap E) \leq P^*(B) + P^*(E) = P^*(E)$, and so $A \in \mathcal{M}(P^*)$.

	Therefore $(\Omega,\mathcal{M}(P^*),P^*)$ is a complete probability space.
\end{proof}

The Borel $\sigma$-field on $(0,1]$, $\mathcal{B}$, together with the Lebesgue measure $\lambda$, can be completed this way. The sets in $\mathcal{M}(\lambda^*)$ are called \emph{Lebesgue sets}. $\lambda^*$ is still called \emph{Lebesgue measure}, and is often denoted simply by $\lambda$. On $\Omega = (0,1]$,

\[
	\mathcal{I} \subset \mathcal{B}_0 \subset \mathcal{B} \subset \mathcal{M}(\lambda^*).
\]

In terms of the classification of the above, this is ($\pi$-system) $\subset$ (field) $\subset$ ($\sigma$-field) $\subset$ (complete Lebesgue $\sigma$-field).

For any probability space $(\Omega,\mathcal{F},P)$, define
\[
	\mathcal{F}^+ = \{A:\;A \triangle B \subset C \textrm{ for some } B,C \in \mathcal{F} \textrm{ satisfying } P(C)=0\}.
\]
\begin{remark}\label{rem:sym-diff}
	We use $\triangle$ as the \emph{symmetric difference} operator.
	\[
		A \triangle B = (A \cap B^c) \cup (A^c \cap B).
	\]
	Notice that $A^c \triangle B^c = A \triangle B$.
\end{remark}

Notice that $A \in \mathcal{F}^+$ implies $A^c \in \mathcal{F}^+$, since $A^c \triangle B^c = A \triangle B \subset C$. If $A \in \mathcal{F}$, then taking $B=A$ and $C=\varnothing$ shows that $\mathcal{F} \subset \mathcal{F}^+$. Finally, $\mathcal{F}^+$ is closed under countable unions: For $A_i \in \mathcal{F}^+$, we can get $B_i,C_i \in \mathcal{F}$ such that $A_i \triangle B_i \subset C_i$.
\begin{align*}
	\left( \bigcup_{i=1}^\infty A_i \right) \cap \left( \bigcup_{j=1}^\infty B_j \right)^c &\subset \bigcup_{i=1}^\infty (A_i \cap B_i^c) \\
	\left( \bigcup_{i=1}^\infty B_i \right) \cap \left( \bigcup_{j=1}^\infty A_j \right)^c &\subset \bigcup_{i=1}^\infty (B_i \cap A_i^c) \\
	\left( \bigcup_{i=1}^\infty A_i \right) \triangle \left( \bigcup_{j=1}^\infty B_j \right) &\subset \bigcup_{i=1}^\infty (A_i \triangle B_i) \subset \bigcup_{i=1}^\infty C_i.
\end{align*}
So $\mathcal{F}^+$ is a $\sigma$-field on $\Omega$ and $\mathcal{F} \subset \mathcal{F}^+$.

We want to extend $P$ from $\mathcal{F}$ onto $\mathcal{F}^+$. For $A \in \mathcal{F}^+$, there exist some $B,C \in \mathcal{F}$ satisfying $P(C)=0$ and $A \triangle B \subset C$. This is directly from the definition of $\mathcal{F}^+$. If we have another two sets $D$ and $E$ from $\mathcal{F}$ that satisfy $A \triangle D \subset E$ and $P(E)=0$, then $B \triangle D \subset C \cup E$, and hence $P(B)=P(D)$. Define $P^+(A)=P(B)$. This $P^+$ is an unambiguous probability measure on $\mathcal{F}^+$.

This completes the derivation of $(\Omega,\mathcal{F}^+,P^+)$, the minimal complete extension of $(\Omega,\mathcal{F},P)$.

\vspace{10pt}
We now turn our attention to $\lambda$, the Lebesgue measure on the Borel $\sigma$-field $\mathcal{B}$. Define the $\oplus$ operator as follows:
\[
	x \oplus y = \begin{cases}
		x+y & \textrm{if } x + y \in (0,1] \\
		x+y-1 & \textrm{otherwise}.
	\end{cases}
\]
The $\oplus$ operator is also defined with respect to a set and a scalar. $A \oplus x = \{a \oplus x:\;a \in A\}$. Now consider the set
\[
	\mathcal{L} = \{A \in \mathcal{B}:\;A \oplus x \in \mathcal{B} \textrm{ and } \lambda(A \oplus x) = \lambda(A)\}.
\]
Since $(A \oplus x)^c = A^c \oplus x$, $\mathcal{L}$ is a $\lambda$-system containing $\mathcal{I}$. By Theorem~\ref{thm:dynkin}, $\mathcal{L}=\mathcal{B}$. Shifting all sets by $x$ did not their measure. In this sense, $\lambda$ is \emph{translation invariant} on $\mathcal{B}$. In fact, we can go even further.

\begin{theorem} \label{thm:trans-invar}
	Lebesgue measure $\lambda^*$ is translation invariant on all subsets of $\Omega$.
\end{theorem}

\begin{proof}
	Let $\mathcal{B}_0$ be the Borel field generated by $\mathcal{I}$. As we have just seen, for $A \in \mathcal{B}_0$, $A \oplus x \in \mathcal{B}_0$ and $\lambda(A \oplus x) = \lambda(A)$. If $B \subset \bigcup_{i=1}^\infty A_i$ for $A_i \in \mathcal{B}_0$, then $B \oplus x \subset \bigcup_{i=1}^\infty (A_i \oplus x)$. Hence
	\[
		\lambda^*(B \oplus x) \leq \sum_{i=1}^\infty \lambda(A_i \oplus x) = \sum_{i=1}^\infty \lambda(A_i),
	\]
	which implies that $\lambda^*(B \oplus x) \leq \lambda^*(B)$. As $B = (B \oplus x) \oplus (1-x)$, it follows that $\lambda^*(B) \leq \lambda^*(B \oplus x)$. So in fact $\lambda^*(B) = \lambda^*(B \oplus x)$. Thus $\lambda^*$ is translation invariant on all subsets of $\Omega$.
\end{proof}

Just because $\lambda^*$ is translation invariant on all subsets of $\Omega$ does not mean that it is a probability measure on all subsets of $\Omega$. It is only a probability measure on sets belonging to a certain class, appropriately named \emph{Lebesgue-measurable sets}.

\begin{definition}[Lebesgue-measurable] \label{def:lebesgue-measurable}
	The sets in $\mathcal{M}=\mathcal{M}(\lambda^*)$ are called \emph{Lebesgue-measurable sets}. $\lambda^*$ (called \emph{Lebesgue measure}) is a probability measure on $\mathcal{M}$.
\end{definition}

It can be proven that $\lambda^*$ is translation-invariant on $\mathcal{M}$ as follows. If $A \in \mathcal{M}$, then $\lambda^*(AE) + \lambda^*(A^cE) \leq \lambda^*(E)$ for all $E \subset \Omega$ because $\lambda^*$ is an outer measure. For any $B \subset \Omega$,
\[
	(B \oplus x) \cap E = (B \oplus x) \cap ((E \oplus (1-x)) \oplus x) = (B \cap (E \oplus (1-x)) \oplus x).
\]
It follows that
\[
	\lambda^*((B \oplus x) \cap E) = \lambda^*(B \cap (E \oplus (1-x)) \oplus x) = \lambda^*(B \cap (E \oplus (1-x))).
\]
So
\[
	\lambda^*((A \oplus x) \cap E) + \lambda^*((A \oplus x)^c \cap E) \leq \lambda^*(E \oplus (1-x)) = \lambda^*(E).
\]
Hence $A \oplus x \in \mathcal{M}$. This establishes that the Lebesgue measure on $\mathcal{M}$ is \emph{translation invariant}.

\vspace{10pt}
Define the relation $\sim$ such that $x \sim y$ if $x \oplus r = y$ for some rational $r \in (0,1]$. This relation partitions $\Omega$ into equivalence classes $\{A_\theta:\;\theta \in \Theta\}$. Construct a set $H$ consisting of exactly one point from each class $A_\theta$. Further define $Q$ to be the set of rationals in $\Omega$ and $H_r = H \oplus r$.

Then $\bigcup_{r \in Q} H_r = \Omega$, and $H_r \cap H_s = \varnothing$ for $r \neq s \in Q$. That is, the $H$'s are disjoint. To see this, consider a particular $x \in \Omega$. Because $\bigcup_\theta A_\theta = \Omega$, there is some $\theta$ such that $x \in A_\theta$. Choose the $y$ from that same $A_\theta$ where $y \in H$. Now suppose $x \in H_r \cap H_s$. Then $x = y+r$, $y \in H$, and $x = y'+s$, $y' \in H$. This is a contradiction, since we built $H$ by taking exactly one element from each $A_\theta$. Thus $H_r \cap H_s = \varnothing$.

Now if $P$ is a translation invariant probability measure on all subsets of $\Omega$, then
\[
	1 = P(\bigcup_{r \in Q} H_r) = \sum_{r \in Q} P(H_r) = \infty \cdot P(H_{(1/2)})
\]
since this is a countably infinite sum. Clearly we have reached a contradiction. Therefore, \emph{there is no translation-invariant probability measure on $2^{(0,1]}$ (all subsets of $(0,1]$)}. This also implies that $\mathcal{M}(\lambda^*) \neq 2^{(0,1]}$, that is, there exists some set that is not Lebesgue-measurable.

\section{Lecture 8, September 11}

\begin{definition}[Monotone class] \index{Monotone class} \label{def:monotone-class}
	A class $\mathcal{M}$ of subsets of $\Omega$ is called a \emph{monotone class} if it is closed under countable monotone limits. That is,
	\begin{enumerate}[label=(\roman*)]
		\item $A_1,A_2,\dots \in \mathcal{M}$ and $A_n \uparrow A$ imply $A \in \mathcal{M}$ and
		\item $A_1,A_2,\dots \in \mathcal{M}$ and $A_n \downarrow A$ imply $A \in \mathcal{M}$.
	\end{enumerate}
\end{definition}

Notice that a class containing only one set is automatically monotone. For example, $\mathcal{M} = \{\varnothing\}$ satisfies the conditions in Definition~\ref{def:monotone-class}.

\begin{theorem} \label{thm:monotone-class}
	If $\mathcal{F}$ is a field and $\mathcal{M}$ is a monotone class, then $\mathcal{F} \subset \mathcal{M}$ implies $\sigma(\mathcal{F}) \subset \mathcal{M}$.
\end{theorem}

\begin{proof}
	First we will show that a class $\mathcal{M}$ that is both monotone and a field is a $\sigma$-field. Take $c_1,c_2,\dots \in \mathcal{M}$. Then $A_n = \bigcup_{i=1}^n c_i \in \mathcal{M}$ (fields contain finite unions). But $A_n \uparrow \bigcup_{i=1}^\infty c_i \in \mathcal{M}$ because $\mathcal{M}$ is closed under countable monotone limits. Thus $\mathcal{M}$ is a $\sigma$-field.

	Now let $\mathcal{M}_0$ be the smallest monotone class containing $\mathcal{F}$. Then $\mathcal{F} \subset \mathcal{M}_0 \subset \mathcal{M}$. Thus it is enough to show that $\mathcal{M}_0$ is a field.

	Define
	\[
		\mathcal{M}_A = \{B \in \mathcal{M}_0:\; A \cap B,\; A \cap B^c \textrm{ and } A^c \cap B \in \mathcal{M}_0\}.
	\]
	Obviously $\mathcal{M}_A \subset \mathcal{M}_0$. Fix $A \in \mathcal{F}$. We want to show that $\mathcal{M}_A$ is a monotone class. To do that, let $B_n \in \mathcal{M}_A$ such that $B_n \uparrow B$. From the definition of $\mathcal{M}_A$ we know that
	\[
		\left.
		\begin{array}{r}
			A \cap B_n \\
			A \cap B_n^c \\
			A^c \cap B_n \\
			B_n
		\end{array}
		\right\} \in \mathcal{M}_0.
	\]

	Taking increasing limits, $B_n \uparrow B \in \mathcal{M}_0$, $A \cap B_n \uparrow A \cap B \in \mathcal{M}_0$, $A^c \cap B_n \uparrow A^c \cap B \in \mathcal{M}_0$, and $A \cap B_n^c \downarrow A \cap B^c \in \mathcal{M}_0$. All this means that $B \in \mathcal{M}_A$. So $\mathcal{M}_A$ is indeed monotone. In fact, this is true for any $A$, not just those in $\mathcal{F}$. (The above argument can be modified slightly to show that if $C_n \in \mathcal{M}_A$ and $C_n \downarrow C$, then $C \in \mathcal{M}_A$.)

	The next step is to show that if $A \in \mathcal{F}$, then $\mathcal{F} \subset \mathcal{M}_A$. Take $A,B \in \mathcal{F}$. Then by definition of $\mathcal{M}_A$, $B \in \mathcal{M}_A$. Hence $\mathcal{M}_0 \subset \mathcal{M}_A$ because $\mathcal{M}_0$ is minimal. However, we already saw that $\mathcal{M}_A \subset \mathcal{M}_0$. Therefore $\mathcal{M}_0 = \mathcal{M}_A$.

	So, for $B \in \mathcal{M}_0$ and $A \in \mathcal{F}$, we know that $A \cap B$, $A \cap B^c$, and $A^c \cap B \in \mathcal{M}_0$. Again, $\mathcal{F} \subset \mathcal{M}_B$ and by minimality $\mathcal{M}_0 = \mathcal{M}_B$.

	Finally, if $A,B \in \mathcal{M}_0 = \mathcal{M}_A$, then $A \cap B$, $A \cap B^c$, and $A^c \cap B \in \mathcal{M}_0$. So $\mathcal{M}_0$ is a field.
\end{proof}

\begin{example} \label{ex:1.7}
	The above theorem requires that $\mathcal{M}$ contain a field $\mathcal{F}$. It does not hold if this requirement is relaxed to, say, $\mathcal{M}$ containing a $\pi$-system. As a counterexample, consider $\mathcal{P} = \mathcal{M} = \{\varnothing\}$, where $\Omega \neq \varnothing$. Clearly $\mathcal{P}$ is a $\pi$-system, and $\mathcal{M}$ contains a single element so it is a monotone class. However, $\sigma(\mathcal{P}) = \{\varnothing, \Omega\} \not\subset \mathcal{M}$.
\end{example}

\chapter{}

\section{Lecture 9, September 14}

\begin{definition}[Lim inf and lim sup] \label{def:limit-sets}
	\begin{align*}
		\liminf_n A_n &= \bigcup_{n=1}^\infty \bigcap_{k=n}^\infty A_k \\
		\limsup_n A_n &= \bigcap_{n=1}^\infty \bigcup_{k=n}^\infty A_k.
	\end{align*}
\end{definition}

Suppose we have a probability space $(\Omega,\mathcal{F},P)$ such that $A_n \in \mathcal{F}$. Then $\liminf_n A_n, \limsup_n A_n \in \mathcal{F}$. So it makes sense to think about $P(\liminf_n A_n)$ and $P(\limsup_n A_n)$. In fact, we will often use the following theorem about these values.

\begin{theorem} \label{thm:2.1}
	For any $A_n$,
	\[
		P\left(\liminf_n A_n\right) \leq \liminf_n P(A_n) \leq \limsup_n P(A_n) \leq P\left(\limsup_n A_n\right).
	\]
\end{theorem}

Note that $A_n \subset \bigcup_{k \geq n} A_k$. So $P(A_n) \leq P \left( \bigcup_{k \geq n} A_k \right) \downarrow P \left( \limsup_n A_n \right)$.

It is possible for the inequalities in Theorem~\ref{thm:2.1} to all be strict, as in the following example.

\begin{example} \label{ex:strict-ineq-liminf-limsup}
	Define a sequence of sets $A_n$ such that $A_{2n+1} = (0,1/3]$ and $A_{2n} = (1/3,1]$. In this situation we have
	\begin{align*}
		P \left( \liminf_n A_n \right) &= 0, \\
		\liminf_n P(A_n) &= \frac{1}{3}, \\
		\limsup_n P(A_n) &= \frac{2}{3}, \textrm{ and} \\
		P \left( \limsup_n A_n \right) &= 1.
	\end{align*}
	Clearly
	\[
		P\left(\liminf_n A_n\right) < \liminf_n P(A_n) < \limsup_n P(A_n) < P\left(\limsup_n A_n\right).
	\]
\end{example}

\begin{definition}[Independent events] \label{def:independent-events}
	Two events $A$ and $B$ are \emph{independent} if $P(AB) = P(A)P(B)$.

	Three events $A$, $B$, and $C$ are independent if all three are pairwise independent with each other, \emph{and} $P(ABC)=P(A)P(B)P(C)$.

	In general, $A_1,\dots,A_n$ are independent if
	\[
		P \left( A_{k_1} \cap \cdots \cap A_{k_j} \right) = P \left( A_{k_1} \right) \cdots P \left( A_{k_j} \right)
	\]
	for $2 \leq j \leq n$ and $1 \leq k_1 < \cdots < k_j \leq n$.
\end{definition}

\begin{example} \label{ex:not-independent}
	Suppose $\Omega = \{1,2,3,4,5,6,7,8\}$, and $P(\{i\}) = \frac{1}{8}$. Define the events
	\[
		A = \{1,2,3,4\}, \qquad B = \{1,2,5,6\}, \qquad C = \{1,2,7,8\}.
	\]
	It is easy to check that any two of $A$, $B$, and $C$ are independent. However, $P(ABC) = \frac{1}{4}$ but $P(A)P(B)P(C) = \frac{1}{8}$.

	Now suppose we define
	\[
		A = \{1,2,3,4\}, \qquad D = \{4,5,6,7\}, \qquad E = \{4,5,6,7\}.
	\]
	Here $P(ADE) = P(A)P(D)P(E) = \frac{1}{8}$, but no two of $A$, $D$, and $E$ are independent. In each of these scenarios, the three events are not independent.
\end{example}

Notice that technically, independence is not a property of the events themselves, but rather of the probability measure $P$.

If we have two events $A,B$ that are independent, what can we say about $A^c$ and $B$?
\begin{align*}
	P(A^c \cap B) &= P(B) - P(A \cap B) \\
	&= P(B) - P(A)P(B) \\
	&= P(B)[1-P(A)] \\
	&= P(B)P(A^c).
\end{align*}
$A^c$ and $B$ are also independent.

\begin{definition}[Independent classes] \label{def:independent-classes}
	The classes $\mathcal{F}_1,\dots,\mathcal{F}_n$ are independent if for every possible choice of $A_i \in \mathcal{F}_i$, $A_1,\dots,A_n$ are independent.

	An infinite collection of classes $\{\mathcal{F}_\theta:\;\theta \in \Theta\}$ is independent if each finite subcollection $\mathcal{F}_{\theta_1}, \dots, \mathcal{F}_{\theta_n}$ of classes is independent.
\end{definition}

\begin{theorem} \label{thm:independent-pi-system}
	$ $
	\begin{itemize}
		\item If $\mathcal{F}_1,\dots,\mathcal{F}_n$ are independent and each $\mathcal{F}_i$ is a $\pi$-system, then $\sigma(\mathcal{F}_1),\dots,\sigma(\mathcal{F}_n)$ are independent.
		\item If the classes $\{\mathcal{F}_\theta:\;\theta \in \Theta\}$ are independent and each $\mathcal{F}_\theta$ is a $\pi$-system, then $\{\mathcal{F}_\theta:\;\theta \in \Theta\}$ are independent.
	\end{itemize}
\end{theorem}

\begin{proof}
	Fix $A_2 \in \mathcal{F}_2, \dots, A_n \in \mathcal{F}_n$. Let
	\[
		\mathcal{G} = \{B \in \sigma(\mathcal{F}_1):\;P(B B_2 \cdots B_n) = P(B)P(B_2) \cdots P(B_n),\;B_i=A_i \textrm{ or } \Omega\}.
	\]
	Clearly $\mathcal{F}_1 \in \mathcal{G}$. Now check that $\mathcal{G}$ is a $\lambda$-system. Recall that this means we need to check
	\begin{itemize}
		\item $\Omega \in \mathcal{G}$
		\item $C \in \mathcal{G}$ implies $C^c \in \mathcal{G}$
		\item For disjoint $C_i \in \mathcal{G}$, $\bigcup_i^\infty C_i \in \mathcal{G}$.
	\end{itemize}
	The first is trivial. For the second, fix some $C \in \mathcal{G}$. That means that $P(C \cap B_2 \cap \cdots \cap B_n) = P(C)P(B_2) \cdots P(B_n)$. We are trying to determine if $P(C^c \cap B_2 \cap \cdots \cap B_n) = P(C^c)P(B_2) \cdots P(B_n)$. Taking the probability of the union of the two left hand sides,
	\begin{align*}
		P \left( (C \cap B_2 \cap \cdots \cap B_n) \cup (C^c \cap B_2 \cap \cdots \cap B_n) \right) &= P \left( \Omega \cap B_2 \cap \cdots \cap B_n \right) \\
		&= P(B_2 \cap \cdots \cap B_n).
	\end{align*}
	Adding the two right hand sides gives
	\begin{align*}
		P(C)P(B_2) \cdots P(B_n) + P(C^c)P(B_2) \cdots P(B_n) &= P(\Omega)P(B_2) \cdots P(B_n) \\
		&= P(B_2) \cdots P(B_n).
	\end{align*}
	Since the $B$s are independent it is indeed true that $P(B_2 \cap \cdots \cap B_n) = P(B_2) \cdots P(B_n)$. So $C^c \in \mathcal{G}$.

	For the third property,
	\begin{align*}
		P \left( \bigcup_i^\infty C_i \cap B_2 \cap \cdots \cap B_n \right) &= \sum_{i=1}^\infty P(C_1 \cap B_2 \cap \cdots \cap B_n) \tag{$C_i$ disjoint} \\
		&= \left( \sum_{i=1}^\infty P(C_i) \right) P(B_2) \cdots P(B_n) \\
		&= P \left( \bigcup_i^\infty C_i \right) P(B_2) \cdots P(B_n). \tag{$C_i$ disjoint}
	\end{align*}
	So $\bigcup_i^\infty C_i \in \mathcal{G}$, and thus $\mathcal{G}$ is a $\lambda$-system, containing the $\pi$-system $\mathcal{F}_1$. Therefore $\mathcal{G} \supset \sigma(\mathcal{F}_1)$.

	Now we can fix $A_1 \in \sigma(\mathcal{F}_1)$, $A_3 \in \mathcal{F}_3, \dots, A_n \in \mathcal{F}_n$. Define
	\[
		\mathcal{G}_2 = \{B \in \sigma(\mathcal{F}_2):\;P(B B_2 \cdots B_n) = P(B)P(B_2) \cdots P(B_n);\;B_i=A_i \textrm{ or } \Omega\}.
	\]
	We can proceed in the exact same way to show that $\mathcal{G}_2 \supset \sigma(\mathcal{F}_2)$, etc. This method suffices to prove that $\sigma(\mathcal{F}_1), \sigma(\mathcal{F}_2), \dots, \sigma(\mathcal{F}_n)$ are independent.
\end{proof}

\begin{corollary}
	Suppose that the array
	\[
	\begin{array}{ccc}
		A_{11} & A_{12} & \cdots \\
		A_{21} & A_{22} & \cdots \\
		\vdots & \vdots & \ddots \\
	\end{array}
	\]
	of events is independent. If $\mathcal{F}_i$ is the $\sigma$-field generated by the $i$th row, then $\mathcal{F}_1,\mathcal{F}_2,\dots$ are independent.
\end{corollary}

\begin{proof}
	If $\mathcal{A}_i$ is the class of all finite intersections of elements of the $i$th row, then each $\mathcal{A}_i$ is a $\pi$-system, and by Theorem~\ref{thm:independent-pi-system}, $\mathcal{F}_i = \sigma(\mathcal{A}_i)$.
\end{proof}

Why is this useful? Say we want to generate a sequence of normal random variables. It turns out that this can be done with just a coin. When we flip a coin $n$ times we are generating the events $Z_1,\dots,Z_n$ where $P(Z_i=1) = P(Z_i=0) = \frac{1}{2}$. Define
\[
	Z_0 = \sum_{i=1}^\infty \frac{Z_i}{2^i}.
\]
Notice that $Z_0 \in [0,1]$ and $P(Z_0 = x) = x$ for $0 < x < 1$. That is, $Z_0$ is uniform on $(0,1)$. We can then generate infinitely many of these by arranging them into an array like the above, and they will all be independent.

\begin{theorem}[Borel-Cantelli Lemmas] \label{thm:borel-cantelli}
	Let $(\Omega,\mathcal{F},P)$ be a probability space, and let $A_i \in \mathcal{F}$.
	\begin{enumerate}
		\item If $\sum_n P(A_n)$ converges, then $P \left( \limsup_n A_n \right) = 0$.
		\item If $\{A_n\}$ are independent and $\sum_n P(A_n)$ diverges, then $P \left( \limsup_n A_n \right) = 1$.
	\end{enumerate}
\end{theorem}

\begin{proof}
	Proof of 1:
	\[
		P \left( \limsup_n A_n \right) \leq P \left( \bigcup_{k=m}^\infty A_k \right) \leq \sum_{k=m}^\infty P(A_k) \xrightarrow[m \to \infty]{} 0.
	\]
	The above uses the countable subadditivity property of $P$.

	Proof of 2: consider the complement. $(\limsup_n A_n)^c = (\bigcap_{n=1}^\infty \bigcup_{k=n}^\infty A_k)^c = \bigcup_{n=1}^\infty \bigcap_{k=n}^\infty A_k^c$.

	\begin{align*}
		P \left( \bigcap_{k=m}^\infty A_k^c \right) &\leq P \left( \bigcap_{k=m}^r A_k^c \right) \tag{nonnegativity} \\
		&= \prod_{k=m}^r (1-P(A_k)) \tag{independence} \\
		&\leq e^{-\sum_{k=m}^r P(A_k)}. \tag{because $1-x \leq e^{-x} \;\; \forall x$}
	\end{align*}

	As $\sum_n P(A_n)$ is a divergent series, $e^{-\sum_{k=m}^r P(A_k)} \to 0$ as $r \to \infty$. So $P(\bigcup_{m=1}^\infty \bigcap_{k=m}^\infty A_k^c) = 0$, and thus the complement $P(\limsup_n A_n) = 1$.
\end{proof}

The Borel-Cantelli Lemmas tell us that if we have infinitely many independent events, $P(\limsup_n A_n) = 0$ or 1 always, regardless of the choice of probability measure $P$.

Is independence necessary for the lemmas to hold? The answer is yes, as the following example illustrates.

\begin{example} \label{ex:2.1}
	Consider the unit interval Lebesgue measure. Define $A = (0,1/3]$ and $B = (2/3,1]$. Let $A_{2n} = A$, $A_{2n+1} = B$. So $A_k$ is an infinite sequence of sets $A, B, A, B, \dots$.

	Now each $P(A_n) = 1/3$, so $\sum P(A_n) = \infty$. However, $\limsup_n A_n = A \cup B$, and so $P(\limsup_n A_n) = 2/3$, not 0 or 1 as the Borel-Cantelli Lemmas guarantee for independent events.
\end{example}

\section{Lecture 10, September 16}

There is a version of Borel-Cantelli that does work for dependent events, however.

\begin{theorem}[Borel-Cantelli Lemma, dependent events] \label{thm:borel-cantelli-dependent}
	Let
	\[
		\theta_n = \frac{\sum_{j=1}^m \sum_{k=1}^n P(A_jA_k)}{\left[ \sum_{k=1}^n P(A_k) \right]^2}.
	\]
	If $\liminf_n \theta_n \leq 1$ and $\sum_n P(A_n) = \infty$, then $P(\limsup_n A_n) = 1$.
\end{theorem}

\begin{proof}
	Let $N_n \sum_{i=1}^n I_{A_j}$ and $m_n = \sum_{k \leq n} P(A_k)$. If $m_n > x$, then
	\begin{align*}
		P(N_n \leq x) &= P(|N_n - m_n| \geq m_n - x) \\
		&\leq \textrm{Var}(N_n)/(m_n - x)^2 \tag{Chebyshev} \\
		&= (\theta_n - 1)m_n^2/(m_n-x)^2. \tag{$N_n$ is binomial}
	\end{align*}
	So $\liminf_n P(N_n \leq x) = 0$. Since $P(\sup_k N_k < x) \leq P(N_n \leq x)$,
	\[
		P(\sup_k N_k < \infty) = P(\bigcup_{m=1}^\infty (\sup_k N_k < m)) = 0.
	\]
	Hence $P(\limsup_n A_n) = P(\sup_n N_n = \infty) = 1$.
\end{proof}

\begin{corollary}
	If $\{A_n\}$ are pairwise independent, and $\sum_n P(A_n) = \infty$, then $P(\limsup_n A_n) = 1$.
\end{corollary}

We will now introduce the concept of a \emph{tail $\sigma$-field}.

\begin{definition}[Tail $\sigma$-field] \label{def:tail-field}
	$\mathcal{T} = \bigcap_{n=1}^\infty \sigma(A_n,A_{n+1},\dots)$ is called the \emph{tail $\sigma$-field} associated with $A_1,A_2,\dots$.
\end{definition}

To understand this conceptually, consider the sequence
\[
	\sigma(A_1,A_2,\dots) \supset \sigma(A_2,A_3,\dots) \supset \sigma(A_3,A_4,\dots).
\]
These are decreasing $\sigma$-fields, and $\mathcal{T}$ is the intersection of all of these. It is usually very small. For example, if $A_1=A_2=\cdots=A$, then $\mathcal{T} = \sigma(\{A\}) = (\varnothing, \Omega, A, A^c)$.

\begin{theorem}[Zero-one law] \label{thm:zero-one}
	If $A_1,A_2,\dots$ are independent, then $P(A)$ is either 0 or 1 for each $A \in \mathcal{T}$.
\end{theorem}

\begin{proof}
	Clearly $\sigma(A_1,\dots,A_n)$ and $\sigma(A_{n+1},\dots)$ are independent for all $n$. $A \in \mathcal{T}$ implies that $A$ and $A_1,\dots,A_n$ are independent, so $A$ and $A_1,A_2,\dots$ are independent. Thus $A$ and $\mathcal{T}$ are independent, and hence $A$ and $A^c$ are independent. So
	\[
		0 = P(A \cap A^c) = P(A)P(A^c) \implies P(A) = 0 \textrm{ or } 1.
	\]
\end{proof}

Suppose $A = \limsup_n A_n$. Is $A \in \mathcal{T}$?
\begin{align*}
	A = \bigcap_{m=1}^\infty \bigcup_{n=m}^\infty A_n &= \{\omega:\;\omega \in A_k \textrm{ for infinitely many } k=1,2,\dots\} \\
	&= \{\omega:\;\omega \in A_k \textrm{ for infinitely many } k=2,3,\dots\} \\
	&= \{\omega:\;\omega \in A_k \textrm{ for infinitely many } k=r,r+1,\dots \textrm{ for any } r\} \\
	&\in \sigma(A_r,A_{r+1},\dots)
\end{align*}
and so $A \in \mathcal{T}$. Also,
\[
	A = \bigcap_{m=1}^\infty \bigcup_{n=m}^\infty A_n = \bigcap_{m=2}^\infty \bigcup_{n=m}^\infty A_n = \bigcap_{m=r}^\infty \bigcup_{n=m}^\infty A_n \in \sigma(A_r,A_{r+1},\dots).
\]

So $\liminf_n$ and $\limsup_n$ are both in the tail $\sigma$-field.

Note that Borel-Cantelli can actually help tell you \emph{when} $P(A)$ is 0 or 1. The zero-one law just tells you that it must be one or the other.

\begin{theorem}[Bernstein's Theorem] \label{thm:bernstein}
	If $f$ is continuous, then $B_n(x) \to f(x)$ uniformly on $[0,1]$, where
	\[
		B_n(x) = \sum_{k=0}^n f(k/n) {n \choose k} x^k (1-x)^{n-k}
	\]
	are Bernstein polynomials.
\end{theorem}

\begin{proof}
	Let $M = \sup_x |f(x)|$, and let $\delta(\epsilon) = \sup[|f(x)-f(y)|:\;|x-y| \leq \epsilon]$. This value is known as the \emph{modulus of continuity} of $f$. It will be shown that
	\[
		\sup_x |f(x) - B_n(x)| \leq \delta(\epsilon) + \frac{2M}{n\epsilon^2}.
	\]
	Because $f$ is uniformly continuous, $\lim_{\epsilon \to 0} \delta(\epsilon) = 0$, and so this inequality (provided we pick a sufficiently small $\epsilon$, say $\epsilon = n^{-1/3}$) will give the result in the theorem.

	Fix $n \geq 1$ and $x \in [0,1]$ for the moment. Let $X_1,\dots,X_n$ be independent random variables (on some probability space) such that $P(X_i=1) = x$ and $P(X_i=0) = 1-x$. Define $S = X_1 + \cdots + X_n$. Since $S$ is just the sum of $n$ Bernoulli random variables, $P(S=k) = {n \choose k} x^k(1-x)^{n-k}$, and by the formula for calculating expected values of functions of random variables, $\textrm{E}[f(S/n)] = B_n(x)$. Additionally, $\textrm{E}[S/n] = x$, so by the law of large numbers, there should be a high probability that $S/n$ is near $x$, and hence (because $f$ is continuous) that $f(S/n) = f(x)$. Therefore, $\textrm{E}[f(S/n)]$ should be near $f(x)$. This is the probabilistic idea behind the definition of the Bernstein polynomial $B_n(x)$.

	For some $\epsilon > 0$, consider the set $\{|S/n-x| < \epsilon\}$. This is the set of values of $x$ that are ``near'' (within $\epsilon$ of) $S/n$. On this set, $|f(S/n) - f(x)|$ is bounded by $\delta(\epsilon)$. On $\{|S/n-x| \geq \epsilon\}$, the complementary set, $|f(S/n) - f(x)|$ is bounded by $2M$. Now
	\begin{align*}
		|B_n(x) - f(x)| &= \big|\textrm{E}[f(S/n) - f(x)]\big| \\
		&\leq \textrm{E}\big[|f(S/n) - f(x)|\big] \\
		&\leq \delta(\epsilon) P \big[|S/n-x| < \epsilon\big] + 2MP \big[|S/n-x| \geq \epsilon\big] \\
		&\leq \delta(\epsilon) + 2M \textrm{Var}[S]/n^2\epsilon^2. \tag{Chebyshev's Inequality}
	\end{align*}
	Since $\textrm{Var}[S] = nx(1-x) \leq n$, we indeed find that
	\[
		\sup_x |f(x) - B_n(x)| \leq \delta(\epsilon) + \frac{2M}{n\epsilon^2}.
	\]
\end{proof}

\section{Lecture 11, September 18}

We can't begin to define constructs like probability density functions without first developing the concept of an \emph{infinite measure}.

\begin{definition}[General measure] \label{def:general-measure}
	A set function $\mu$ on a field $\mathcal{F}$ on $\Omega$ is a \emph{measure} if it satisfies
	\begin{enumerate}[label=(\Roman*)]
		\item $0 \leq \mu(A) \leq \infty$ for $A \in \mathcal{F}$
		\item $\mu(\varphi) = 0$
		\item If $\{A_n\}$ is a sequence of disjoint sets in $\mathcal{F}$ and if $\bigcup_{n=1}^\infty A_n \in \mathcal{F}$, then
		\[
			\mu \left( \bigcup_{n=1}^\infty A_n \right) = \sum_{n=1}^\infty \mu(A_n).
		\]
	\end{enumerate}
	Furthermore, $\mu$ is a \emph{finite measure} if $\mu(\Omega) < \infty$. On the other hand, $\mu$ is an \emph{infinite measure} if $\mu(\Omega) = \infty$.
\end{definition}

\begin{definition}[$\sigma$-finite measure] \label{def:sigma-finite-measure}
	$\mu$ is a \emph{$\sigma$-finite measure} if $\Omega = A_1 \cup A_2 \cup \cdots$ for some finite or countable sequence of sets in $\mathcal{F}$ satisfying $\mu(A_k) < \infty$.
\end{definition}

A finite measure is by definition $\sigma$-finite, but a $\sigma$-finite measure may by finite or infinite. If $\mathcal{A}$ is a subclass of $\mathcal{F}$, then $\mu$ is \emph{$\sigma$-finite on $\mathcal{A}$} if $\Omega = \bigcup_k A_k$ for some finite or infinite sequence of sets in $\mathcal{A}$ satisfying $\mu(A_k) < \infty$. These sets need not necessarily be disjoint. It is important to understand that $\sigma$-finiteness is a joint property of the space $\Omega$, the measure $\mu$, and the class $\mathcal{A}$.

Results about probability measures can be extended to finite measures simply by redefining
\[
	P(A) = \frac{\mu(A)}{\mu(\Omega)}.
\]
We can extend to $\sigma$-finite measures as well, since they are actually made up of finite intervals: $\Omega = \bigcup_k A_k$, $A_k \in \mathcal{F}$, and $\mu(A_i) < \infty$. For example, the real line can be written
\[
	\mathbb{R} = \bigcup_{n=1}^\infty (-n,n) = \bigcup_{m=-\infty}^\infty (m,m+1].
\]

\begin{example}[Counting measure] \label{ex:counting-measure}
	Suppose $\Omega = \{1,2,3,\dots\}$ and $\mathcal{F}$ consists of all subsets of $\Omega$. Define $\mu(A)$ to be the number of points in $A$ if $A$ is a finite set, and $\infty$ otherwise. This $\mu$ is called the \emph{counting measure}, for obvious reasons.

	We can write $\Omega = \bigcup_{n=1}^\infty \{n\}$, and $\mu(\{n\}) = 1 < \infty$ for all $n$. So $\mu$ is $\sigma$-finite.

	Now suppose instead that $\Omega = \mathbb{R}$. In this case, $\mu(\textrm{any interval}) = \infty$. To write $\mathbb{R} = \Omega = \bigcup_i A_i$, at least one of the $A_i$ must be infinite. So $\mu$ is not $\sigma$-finite.
\end{example}

\begin{example} \label{ex:sigma-finite-measure-restricting}
	The restriction of a $\sigma$-finite measure to a smaller $\sigma$-field may not necessarily be $\sigma$-finite itself. The counting measure is not $\sigma$-finite on $\{\varnothing, \Omega\}$ if $\Omega$ is a countably infinite set.
\end{example}

\begin{theorem} \label{thm:measure-properties}
	Let $\mu$ be a measure on a field $\mathcal{F}$ and $A_n, A \in \mathcal{F}$.
	\begin{enumerate}[label=(\Roman*)]
		\item \emph{Continuity from below}: if $A_n \uparrow A$, then $\mu(A_n) \uparrow \mu(A)$.
		\item \emph{Continuity from above}: if $A_n \downarrow A$, and $\mu(A_k) < \infty$ for some $k$, then $\mu(A_n) \downarrow \mu(A)$.
		\item \emph{Countable subadditivity}:
		\[
			\mu \left( \bigcup_{n=1}^\infty A_n \right) \leq \sum_{n=1}^\infty \mu(A_n).
		\]
		\item If $\mu$ is $\sigma$-finite on $\mathcal{F}$, then $\mathcal{F}$ cannot contain an uncountable, disjoint collection of sets of positive $\mu$-measure.
	\end{enumerate}
\end{theorem}

Notice the extra condition in (II). A simple example demonstrating why this is necessary is as follows. Suppose $\Omega = \{1,2,\dots\}$ and $\mathcal{F}$ consists of all subsets of $\Omega$. Define $\mu$ to be the counting measure as before. Now let $A_n = \{n,n+1,\dots\}$. Then $A_n \downarrow \varnothing$, and $\mu(\varnothing) = 0$, yet $\mu(A_n) = \infty$ for all $n$. So clearly $\mu(A_n)$ does not converge to $\mu(\varnothing)$.

\section{Lecture 12, September 23}

\begin{theorem} \label{thm:general-measure-agree}
	Suppose that $\mu_1$ and $\mu_2$ are measures on $\sigma(\mathcal{P})$, where $\mathcal{P}$ is a $\pi$-system, and suppose they are are $\sigma$-finite on $\mathcal{P}$. If $\mu_1$ and $\mu_2$ agree on $\mathcal{P}$, then they agree on $\sigma(\mathcal{P})$.
\end{theorem}

\begin{proof}
	Suppose $A \in \mathcal{P}$, and $0 < \mu_1(A) = \mu_2(A) < \infty$. Define the class
	\[
		\mathcal{G} = \{B \in \sigma(\mathcal{P}):\;\mu_1(A \cap B) = \mu_2(A \cap B)\}.
	\]
	Now $\mathcal{P} \subset \mathcal{G}$. And $B \in \mathcal{P}$ implies $A \cap B \in \mathcal{P}$, since $A \in \mathcal{P}$ and $\mathcal{P}$ is a $\pi$-system. Also,
	\begin{align*}
		B \in \mathcal{G} \implies \mu_1(A \cap B^c) &= \mu_1(A) - \mu_1(A \cap B) \\
		&= \mu_2(A) - \mu_2(A \cap B) = \mu_2(A \cap B^c).
	\end{align*}
	So $\mathcal{G}$ is closed under complementation.

	Now take $B_1,B_2,\dots$ disjoint.
	\begin{align*}
		\mu_1 \left( A \cap \bigcup_{i=1}^\infty B_i \right) &= \sum_i \mu_i(A \cap B_i) \\
		&= \sum_i \mu_2(A \cap B_i) \\
		&= \mu_2 \left( A \cap \bigcup_{i=1}^\infty B_i \right),
	\end{align*}
	so $\mathcal{G}$ is closed under countable union. Thus $\mathcal{G}$ is a $\lambda$-system, and it contains a $\pi$-system $\mathcal{P}$. Thus $\mathcal{G} \supset \sigma(\mathcal{P})$. Clearly $\mathcal{G} \subset \sigma(\mathcal{P})$. Therefore $\mathcal{G}=\sigma(\mathcal{P})$. And so $\mu_1$ and $\mu_2$ agree on $\sigma(\mathcal{P})$.
\end{proof}

\begin{theorem} \label{thm:general-measure-agree-2}
	Suppose $\mu_1$ and $\mu_2$ are finite measures on $\sigma(\mathcal{P})$, where $\mathcal{P}$ is a $\pi$-system and $\Omega$ is a finite or countable union of sets in $\mathcal{P}$. If $\mu_1$ and $\mu_2$ agree on $\mathcal{P}$, then they agree on $\sigma(\mathcal{P})$.
\end{theorem}

\begin{example}[Counterexample to Theorem~\ref{thm:general-measure-agree-2}] \label{ex:2.2}
	Suppose $\mathcal{P} = \{\varnothing\}$. Then $\mathcal{P}$ is a $\pi$-system and $\sigma(\mathcal{P}) = \{\Omega,\varnothing\}$. Any two finite measures agree on $\mathcal{P}$, but they do not necessarily agree on $\sigma(\mathcal{P})$. Theorem~\ref{thm:general-measure-agree-2} does not apply in this case because $\Omega$ is not a countable union of sets in $\mathcal{P}$.
\end{example}

\begin{definition}[Outer measure] \label{def:outer-measure}
	An \emph{outer measure} is a set function $\mu^*$ on all subsets of $\Omega$ satisfying:
	\begin{enumerate}[label=(\roman*)]
		\item $\mu^*(\varnothing) = 0$
		\item $0 \leq \mu^*(A) \leq \infty$ for all $A \subset \Omega$
		\item $\mu^*(A) \leq \mu^*(B)$ whenever $A \subset B$
		\item $\mu^*(\bigcup_i A_i) \leq \sum_i \mu^*(A_i)$ (Countable subadditivity)
	\end{enumerate}
\end{definition}

\begin{theorem} \label{thm:outer-measure}
	Recall the class definition from earlier.
	\[
		\mathcal{M}(\mu^*) = \{A \subset \Omega:\;\mu^*(AE) + \mu^*(A^cE) \leq \mu^*(E) \textrm{ for all } E \subset \Omega\}.
	\]
	If $\mu^*$ is an outer measure, then $\mathcal{M}(\mu^*)$ is a $\sigma$-field, and $\mu^*$ restricted to $\mathcal{M}(\mu^*)$ is a measure.
\end{theorem}

\begin{theorem}[Extension theorem, general measures] \label{thm:general-measure-extension}
	A measure $\mu$ on a field $\mathcal{F}_0$ has an extension to the generating $\sigma$-field.
\end{theorem}

\begin{proof}
	It is enough to show that 
\end{proof}

%----------------------------------------------------------------------------------------
%	BIBLIOGRAPHY
%----------------------------------------------------------------------------------------

\chapter*{Bibliography}
\addcontentsline{toc}{chapter}{\textcolor{ocre}{Bibliography}}
\section*{Books}
\addcontentsline{toc}{section}{Books}
\printbibliography[heading=bibempty,type=book]
\section*{Articles}
\addcontentsline{toc}{section}{Articles}
\printbibliography[heading=bibempty,type=article]

%----------------------------------------------------------------------------------------
%	INDEX
%----------------------------------------------------------------------------------------

\cleardoublepage
\phantomsection
\setlength{\columnsep}{0.75cm}
\addcontentsline{toc}{chapter}{\textcolor{ocre}{Index}}
\printindex

%----------------------------------------------------------------------------------------

\end{document}